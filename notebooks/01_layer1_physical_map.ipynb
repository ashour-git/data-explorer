{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230f1def",
   "metadata": {},
   "source": [
    "# Layer 1: Physical Map - Database Structure and Data Exploration\n",
    "\n",
    "Interactive exploration of table sizes, row counts, column profiling, nullness analysis, and data distributions.\n",
    "\n",
    "**Author:** Data Archaeologist Team  \n",
    "**Version:** 2.0  \n",
    "**Date:** 2025-08-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65316001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Essential imports for data analysis and visualization\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data Archaeologist imports - corrected class names\n",
    "sys.path.append('..')\n",
    "from data_archaeologist.core.database_connection import DatabaseConnection\n",
    "from data_archaeologist.layer1_physical.database_inventory import DatabaseInventory\n",
    "from data_archaeologist.layer1_physical.table_sizing import TableSizingAnalyzer\n",
    "from data_archaeologist.layer1_physical.column_profiling import ColumnProfiler\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e19e556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement matplotlib.pyplot (from versions: none)\n",
      "ERROR: No matching distribution found for matplotlib.pyplot\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6858a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available environments: ['staging', 'production', 'backup']\n",
      "Analysis settings: {'enable_parallel_execution': True, 'max_workers': 3, 'connection_pool_size': 10, 'query_timeout': 300, 'large_table_threshold': 1000000, 'sample_size_for_analysis': 10000, 'top_n_tables': 20, 'sampling_rows': 100000, 'parallel_envs': True}\n",
      "‚úì Database connection initialized\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Environment Setup\n",
    "import json\n",
    "\n",
    "config_file = '../config.json'\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "environments = list(config['environments'].keys())\n",
    "analysis_settings = config.get('analysis_settings', {})\n",
    "\n",
    "print(f\"Available environments: {environments}\")\n",
    "print(f\"Analysis settings: {analysis_settings}\")\n",
    "\n",
    "# Initialize database connection (staging environment)\n",
    "db_conn = DatabaseConnection(config_file)\n",
    "print(\"‚úì Database connection initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e739c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setting up interactive interface...\n",
      "‚úì Environment dropdown created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd231c7ce1643e38f0a28b65316e09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Data Archaeologist - Layer 1 Physical Map</h3>'), Dropdown(description='Environ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Interactive interface initialized\n"
     ]
    }
   ],
   "source": [
    "# Interactive environment, schema, and table selection\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"‚úì Setting up interactive interface...\")\n",
    "\n",
    "# Environment selector\n",
    "env_dropdown = widgets.Dropdown(\n",
    "    options=environments,\n",
    "    value=environments[0] if environments else None,\n",
    "    description='Environment:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "print(\"‚úì Environment dropdown created\")\n",
    "\n",
    "# For now, let's create a simplified version without the complex interactions\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Data Archaeologist - Layer 1 Physical Map</h3>\"),\n",
    "    env_dropdown,\n",
    "    widgets.HTML(\"<p>Selected Environment: Use the dropdown above to select environment</p>\")\n",
    "]))\n",
    "\n",
    "print(\"‚úì Interactive interface initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac9d3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9087a3f31a684d22830949d700fee5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='primary', description='Analyze Top Tables', icon='chart-bar', style=Button‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize top-N tables by size and rows\n",
    "\n",
    "def analyze_top_tables(environment, n=20):\n",
    "    \"\"\"Analyze and visualize top N tables by size.\"\"\"\n",
    "    print(f\"Analyzing top {n} tables in {environment}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get table summary\n",
    "        table_summary = get_table_summary(db_connection, environment)\n",
    "        \n",
    "        if not table_summary:\n",
    "            print(\"No tables found\")\n",
    "            return\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(table_summary)\n",
    "        df = df.head(n)  # Top N tables\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Top Tables by Size (Bytes)',\n",
    "                'Top Tables by Row Count',\n",
    "                'Size vs Row Count Correlation',\n",
    "                'Schema Distribution'\n",
    "            ),\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"type\": \"pie\"}]]\n",
    "        )\n",
    "        \n",
    "        # Top tables by size\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['full_table_name'],\n",
    "                y=df['size_bytes'],\n",
    "                name='Size (Bytes)',\n",
    "                text=df['size_human'],\n",
    "                textposition='auto'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Top tables by row count\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['full_table_name'],\n",
    "                y=df['rows'],\n",
    "                name='Row Count',\n",
    "                marker_color='orange'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Size vs Row correlation\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df['rows'],\n",
    "                y=df['size_bytes'],\n",
    "                mode='markers',\n",
    "                text=df['full_table_name'],\n",
    "                name='Tables',\n",
    "                marker=dict(size=8, color='green')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Schema distribution\n",
    "        schema_counts = df['schema'].value_counts()\n",
    "        fig.add_trace(\n",
    "            go.Pie(\n",
    "                labels=schema_counts.index,\n",
    "                values=schema_counts.values,\n",
    "                name='Schemas'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            title_text=f\"Physical Analysis - {environment.title()} Environment\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        fig.update_xaxes(tickangle=45, row=1, col=1)\n",
    "        fig.update_xaxes(tickangle=45, row=1, col=2)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nüìä Summary Statistics:\")\n",
    "        print(f\"Total tables analyzed: {len(df)}\")\n",
    "        print(f\"Largest table: {df.iloc[0]['full_table_name']} ({df.iloc[0]['size_human']})\")\n",
    "        print(f\"Most rows: {df.loc[df['rows'].idxmax()]['full_table_name']} ({df['rows'].max():,} rows)\")\n",
    "        print(f\"Total size: {df['size_bytes'].sum() / (1024**3):.2f} GB\")\n",
    "        print(f\"Total rows: {df['rows'].sum():,}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Interactive analysis button\n",
    "analyze_button = widgets.Button(\n",
    "    description='Analyze Top Tables',\n",
    "    button_style='primary',\n",
    "    icon='chart-bar'\n",
    ")\n",
    "\n",
    "analysis_output = widgets.Output()\n",
    "\n",
    "def on_analyze_click(b):\n",
    "    with analysis_output:\n",
    "        analysis_output.clear_output()\n",
    "        env = env_dropdown.value\n",
    "        if env:\n",
    "            analyze_top_tables(env, top_n_tables)\n",
    "        else:\n",
    "            print(\"Please select an environment first\")\n",
    "\n",
    "analyze_button.on_click(on_analyze_click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    analyze_button,\n",
    "    analysis_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2882a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0653f80e684d4fa18a340106c248940a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description='Analyze Selected Table Columns', icon='table', style=B‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Column-level analysis for selected table\n",
    "\n",
    "def analyze_table_columns(environment, schema, table):\n",
    "    \"\"\"Analyze columns of a specific table.\"\"\"\n",
    "    print(f\"Analyzing columns of {schema}.{table}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get column information\n",
    "        column_query = \"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type,\n",
    "            character_maximum_length,\n",
    "            is_nullable,\n",
    "            column_default,\n",
    "            ordinal_position\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = %s AND table_name = %s\n",
    "        ORDER BY ordinal_position\n",
    "        \"\"\"\n",
    "        \n",
    "        columns = db_connection.execute_query(environment, column_query, (schema, table))\n",
    "        \n",
    "        if not columns:\n",
    "            print(\"No column information found\")\n",
    "            return\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        columns_df = pd.DataFrame(columns)\n",
    "        \n",
    "        # Analyze nullness\n",
    "        null_analysis = []\n",
    "        \n",
    "        for col in columns:\n",
    "            col_name = col['column_name']\n",
    "            \n",
    "            # Get null percentage\n",
    "            null_query = f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_rows,\n",
    "                COUNT(\\\"{col_name}\\\") as non_null_rows,\n",
    "                (COUNT(*) - COUNT(\\\"{col_name}\\\")) as null_rows,\n",
    "                ROUND(((COUNT(*) - COUNT(\\\"{col_name}\\\")) * 100.0 / COUNT(*)), 2) as null_percentage\n",
    "            FROM \\\"{schema}\\\".\\\"{table}\\\"\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                result = db_connection.execute_query(environment, null_query)\n",
    "                if result:\n",
    "                    null_analysis.append({\n",
    "                        'column_name': col_name,\n",
    "                        'data_type': col['data_type'],\n",
    "                        'is_nullable': col['is_nullable'],\n",
    "                        'null_percentage': result[0]['null_percentage'],\n",
    "                        'null_rows': result[0]['null_rows'],\n",
    "                        'total_rows': result[0]['total_rows']\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not analyze nullness for {col_name}: {e}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        if null_analysis:\n",
    "            null_df = pd.DataFrame(null_analysis)\n",
    "            \n",
    "            # Create subplots\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=(\n",
    "                    'Null Percentage by Column',\n",
    "                    'Data Type Distribution',\n",
    "                    'Nullable vs Non-Nullable Columns',\n",
    "                    'Column Details'\n",
    "                ),\n",
    "                specs=[[{\"secondary_y\": False}, {\"type\": \"pie\"}],\n",
    "                       [{\"type\": \"pie\"}, {\"type\": \"table\"}]]\n",
    "            )\n",
    "            \n",
    "            # Null percentage chart\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=null_df['column_name'],\n",
    "                    y=null_df['null_percentage'],\n",
    "                    name='Null %',\n",
    "                    marker_color='red'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Data type distribution\n",
    "            type_counts = columns_df['data_type'].value_counts()\n",
    "            fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=type_counts.index,\n",
    "                    values=type_counts.values,\n",
    "                    name='Data Types'\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            # Nullable distribution\n",
    "            nullable_counts = columns_df['is_nullable'].value_counts()\n",
    "            fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=['Nullable' if x == 'YES' else 'Not Nullable' for x in nullable_counts.index],\n",
    "                    values=nullable_counts.values,\n",
    "                    name='Nullable'\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Column details table\n",
    "            fig.add_trace(\n",
    "                go.Table(\n",
    "                    header=dict(\n",
    "                        values=['Column', 'Type', 'Nullable', 'Null %'],\n",
    "                        fill_color='paleturquoise',\n",
    "                        align='left'\n",
    "                    ),\n",
    "                    cells=dict(\n",
    "                        values=[\n",
    "                            null_df['column_name'],\n",
    "                            null_df['data_type'],\n",
    "                            null_df['is_nullable'],\n",
    "                            null_df['null_percentage']\n",
    "                        ],\n",
    "                        fill_color='lavender',\n",
    "                        align='left'\n",
    "                    )\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                height=800,\n",
    "                title_text=f\"Column Analysis - {schema}.{table}\",\n",
    "                showlegend=False\n",
    "            )\n",
    "            \n",
    "            fig.update_xaxes(tickangle=45, row=1, col=1)\n",
    "            \n",
    "            fig.show()\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nüìä Column Summary:\")\n",
    "            print(f\"Total columns: {len(columns_df)}\")\n",
    "            print(f\"Nullable columns: {len(columns_df[columns_df['is_nullable'] == 'YES'])}\")\n",
    "            print(f\"Columns with nulls: {len(null_df[null_df['null_percentage'] > 0])}\")\n",
    "            print(f\"Highest null percentage: {null_df['null_percentage'].max():.2f}%\")\n",
    "            \n",
    "            return null_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in column analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Interactive column analysis button\n",
    "column_button = widgets.Button(\n",
    "    description='Analyze Selected Table Columns',\n",
    "    button_style='info',\n",
    "    icon='table'\n",
    ")\n",
    "\n",
    "column_output = widgets.Output()\n",
    "\n",
    "def on_column_click(b):\n",
    "    with column_output:\n",
    "        column_output.clear_output()\n",
    "        env = env_dropdown.value\n",
    "        schema = schema_dropdown.value\n",
    "        table = table_dropdown.value\n",
    "        \n",
    "        if env and schema and table:\n",
    "            analyze_table_columns(env, schema, table)\n",
    "        else:\n",
    "            print(\"Please select environment, schema, and table first\")\n",
    "\n",
    "column_button.on_click(on_column_click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    column_button,\n",
    "    column_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508b557",
   "metadata": {},
   "source": [
    "## Layer 1 Analysis Complete ‚úÖ\n",
    "\n",
    "This notebook provided physical-level analysis including:\n",
    "\n",
    "- **Table Size Analysis** - Top N tables by size and row count\n",
    "- **Schema Distribution** - How tables are distributed across schemas\n",
    "- **Column Profiling** - Data types, nullness analysis, and column characteristics\n",
    "- **Data Quality Insights** - Null percentages and data integrity overview\n",
    "\n",
    "### Key Insights:\n",
    "- Use the interactive widgets to explore different environments and tables\n",
    "- Focus on tables with high null percentages for data quality improvements\n",
    "- Large tables may benefit from partitioning or archival strategies\n",
    "- Schema distribution can inform database organization decisions\n",
    "\n",
    "### Next Steps:\n",
    "- **02_layer2_logical_blueprint.ipynb** - Explore relationships, keys, and logical structure\n",
    "- **03_layer3_business_story.ipynb** - Discover business processes and insights\n",
    "- **04_multi_env_parallel_run.ipynb** - Compare findings across environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
